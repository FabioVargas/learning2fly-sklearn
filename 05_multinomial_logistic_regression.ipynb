{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Multinomial Logistic Regression\n",
    "\n",
    "**Purpose:** Learn and revise **Multinomial Logistic Regression** (multi-class classification) in Scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Multinomial Logistic Regression?\n",
    "\n",
    "**Multinomial logistic regression** extends logistic regression to **more than two classes** (e.g. class 0, 1, 2, ...). For each class \\( k \\), we have a linear score \\( z*k = \\beta*{k0} + \\beta\\_{k1} x_1 + \\ldots \\). Probabilities are given by the **softmax** function:\n",
    "\n",
    "\\[\n",
    "P(y=k \\mid X) = \\frac{e^{z_k}}{\\sum_j e^{z_j}}\n",
    "\\]\n",
    "\n",
    "- The class with the **highest probability** is the predicted class.\n",
    "- In Scikit-learn, **LogisticRegression** with **multi_class='multinomial'** (and solver that supports it, e.g. 'lbfgs') does this. It is the default for \\( K > 2 \\) when using 'lbfgs' or 'newton-cg'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts to Remember\n",
    "\n",
    "| Concept               | Description                                                                                    |\n",
    "| --------------------- | ---------------------------------------------------------------------------------------------- |\n",
    "| **Softmax**           | Converts scores \\( z_k \\) into probabilities that sum to 1.                                    |\n",
    "| **One-vs-Rest (OvR)** | Alternative: train one binary classifier per class; predict the class with highest confidence. |\n",
    "| **multinomial**       | Single model with K coefficient vectors; naturally handles multiple classes.                   |\n",
    "| **When to use**       | Multi-class classification when you want class probabilities and a linear decision boundary.   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three classes (three blobs)\n",
    "np.random.seed(42)\n",
    "X0 = np.random.randn(40, 2) + np.array([0, 2])\n",
    "X1 = np.random.randn(40, 2) + np.array([2, 0])\n",
    "X2 = np.random.randn(40, 2) + np.array([2, 2])\n",
    "X = np.vstack([X0, X1, X2])\n",
    "y = np.array([0]*40 + [1]*40 + [2]*40)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LogisticRegression.__init__() got an unexpected keyword argument 'multi_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlbfgs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m model.fit(X_train, y_train)\n\u001b[32m      3\u001b[39m y_pred = model.predict(X_test)\n",
      "\u001b[31mTypeError\u001b[39m: LogisticRegression.__init__() got an unexpected keyword argument 'multi_class'"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='auto', solver='lbfgs', random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision regions (multiclass)\n",
    "h = 0.05\n",
    "x_min, x_max = X[:, 0].min()-0.5, X[:, 0].max()+0.5\n",
    "y_min, y_max = X[:, 1].min()-0.5, X[:, 1].max()+0.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, levels=2)\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], alpha=0.8, label=\"Class 0\")\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], alpha=0.8, label=\"Class 1\")\n",
    "plt.scatter(X[y==2, 0], X[y==2, 1], alpha=0.8, label=\"Class 2\")\n",
    "plt.xlabel(\"X1\"); plt.ylabel(\"X2\")\n",
    "plt.legend(); plt.title(\"Multinomial Logistic Regression\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Use **LogisticRegression** with **multi_class='multinomial'** and **solver='lbfgs'** (or 'newton-cg') for true multinomial loss.\n",
    "- **model.coef\\_** has shape (n*classes, n_features); \\*\\*model.intercept*\\*\\* has shape (n_classes,).\n",
    "- **predict_proba** returns a matrix of shape (n_samples, n_classes).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
