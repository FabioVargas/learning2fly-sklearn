{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Bernoulli Naive Bayes\n",
    "\n",
    "**Purpose:** Learn and revise **Bernoulli Naive Bayes** in Scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Bernoulli Naive Bayes?\n",
    "\n",
    "**Bernoulli Naive Bayes** assumes each feature is **binary** (0 or 1). It models the probability that feature \\( j \\) equals 1 given class \\( y \\):\n",
    "\n",
    "\\[\n",
    "P(x_j = 1 \\mid y) = p_{jy}\n",
    "\\]\n",
    "\n",
    "Each \\( p_{jy} \\) is estimated from the training data (e.g. fraction of samples in class \\( y \\) where \\( x_j = 1 \\)). The likelihood for a sample \\( X \\) is:\n",
    "\n",
    "\\[\n",
    "P(X \\mid y) = \\prod_{j} p_{jy}^{x_j} (1 - p_{jy})^{1-x_j}\n",
    "\\]\n",
    "\n",
    "- **When to use:** Binary/Boolean features (e.g. word present/absent in text, yes/no flags). In Scikit-learn, **BernoulliNB** binarizes input by default (threshold 0) so you can also feed count-like data; it then treats it as binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts to Remember\n",
    "\n",
    "| Concept | Description |\n",
    "|--------|-------------|\n",
    "| **Binary features** | Each \\( x_j \\in \\{0, 1\\} \\); model learns \\( P(x_j=1 \\mid y) \\) per class. |\n",
    "| **Binarize** | If you pass counts, set **binarize** to a threshold (e.g. 0); values > threshold become 1. |\n",
    "| **Laplace smoothing** | **alpha** adds a small count to avoid zero probabilities. |\n",
    "| **vs Multinomial NB** | Bernoulli: \"word present or not\"; Multinomial: \"how many times\" (counts). |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Binary features: 5 features, two classes\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "X = np.random.randint(0, 2, size=(n, 5))  # 0/1 only\n",
    "y = (X[:, 0] + X[:, 1] + np.random.randint(0, 2, n)) % 2  # loosely related to first 2 features\n",
    "y = np.clip(y, 0, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = BernoulliNB(alpha=1.0)  # Laplace smoothing\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **BernoulliNB** expects (or binarizes to) **binary** features. Use for presence/absence data.\n",
    "- **alpha**: smoothing parameter; helps when a feature never appears in a class (avoids \\( P=0 \\)).\n",
    "- **binarize**: If None, input is assumed binary; set to a number to threshold continuous/count inputs to 0/1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
