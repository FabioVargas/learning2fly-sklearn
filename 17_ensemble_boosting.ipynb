{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Ensemble Learning: Boosting\n",
    "\n",
    "**Purpose:** Learn and revise **Boosting** (AdaBoost, Gradient Boosting) in Scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Boosting?\n",
    "\n",
    "**Boosting** builds an ensemble **sequentially**: each new model focuses on the **mistakes** of the previous ones. AdaBoost reweights misclassified samples; Gradient Boosting fits new trees to the **residuals** of the current ensemble.\n",
    "\n",
    "**Key idea:** Many **weak learners** (e.g. shallow trees) combine into a strong one; reduces **bias**. Tune **n_estimators**, **learning_rate**, and **max_depth**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts to Remember\n",
    "\n",
    "| Concept | Description |\n",
    "|--------|-------------|\n",
    "| **AdaBoost** | Sample weights updated by errors; base estimator fit to weighted data. |\n",
    "| **Gradient Boosting** | Each tree fits residuals; learning_rate shrinks each contribution. |\n",
    "| **n_estimators** | Number of weak learners. |\n",
    "| **learning_rate** | Shrinks each model; smaller = need more estimators. |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.randn(300, 4)\n",
    "y = (X[:, 0] + X[:, 1]**2 > 0.5).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "print(\"AdaBoost:\", accuracy_score(y_test, ada.predict(X_test)))\n",
    "print(\"Gradient Boosting:\", accuracy_score(y_test, gb.predict(X_test)))\n",
    "print(classification_report(y_test, gb.predict(X_test)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **AdaBoostClassifier** / **GradientBoostingClassifier**; **HistGradientBoostingClassifier** for large data.\n",
    "- Tune **n_estimators** and **learning_rate**; **feature_importances_** available for tree-based boosters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
  "language_info": { "name": "python", "version": "3.10.0" }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
