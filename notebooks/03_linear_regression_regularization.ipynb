{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Regression with Regularization\n",
    "\n",
    "**Purpose:** Learn and revise **Ridge**, **Lasso**, and **ElasticNet** regression in Scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Regularization?\n",
    "\n",
    "Standard linear regression can **overfit** when there are many features or correlated features. **Regularization** adds a penalty on the size of coefficients to keep the model simpler and more stable.\n",
    "\n",
    "**Three main types:**\n",
    "\n",
    "1. **Ridge (L2):** Penalizes \\( \\sum \\beta_j^2 \\). Shrinks coefficients toward zero; rarely makes them exactly zero.\n",
    "2. **Lasso (L1):** Penalizes \\( \\sum |\\beta_j| \\). Can set some coefficients to **exactly zero** → feature selection.\n",
    "3. **ElasticNet:** Combines L1 + L2. Good when you have many correlated features.\n",
    "\n",
    "Loss = **MSE** + **penalty**. The strength of the penalty is controlled by \\( \\alpha \\) (and \\( l1_ratio \\) for ElasticNet).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts to Remember\n",
    "\n",
    "| Concept        | Description                                                                           |\n",
    "| -------------- | ------------------------------------------------------------------------------------- |\n",
    "| **Ridge**      | L2 penalty; stable with correlated features; all predictors stay in the model.        |\n",
    "| **Lasso**      | L1 penalty; can zero out coefficients → automatic feature selection.                  |\n",
    "| **ElasticNet** | Mix of L1 and L2; \\( l1_ratio \\) controls the mix (1 = Lasso, 0 = Ridge).             |\n",
    "| **Alpha (α)**  | Larger α = stronger regularization = smaller coefficients. Tune via cross-validation. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n = 100\n",
    "X = np.random.randn(n, 5)  # 5 features, some correlation\n",
    "X[:, 1] = X[:, 0] + 0.1 * np.random.randn(n)  # correlate with feature 0\n",
    "beta_true = np.array([3, 0, 1, 0, 2])  # true coeffs; some zero\n",
    "y = X @ beta_true + np.random.randn(n) * 0.5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge - MSE: 0.2462, R²: 0.9793\n",
      "  Coefficients: [2.17838152 0.42735987 1.00945282 0.02641522 2.19124853]\n",
      "Lasso - MSE: 1.1590, R²: 0.9028\n",
      "  Coefficients: [2.0353725  0.         0.55195666 0.         1.66773427]\n",
      "ElasticNet - MSE: 1.2033, R²: 0.8991\n",
      "  Coefficients: [1.03994021 0.97245248 0.64748553 0.         1.52395823]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5  # regularization strength\n",
    "\n",
    "ridge = Ridge(alpha=alpha).fit(X_train_s, y_train)\n",
    "lasso = Lasso(alpha=alpha).fit(X_train_s, y_train)\n",
    "elastic = ElasticNet(alpha=alpha, l1_ratio=0.5).fit(X_train_s, y_train)\n",
    "\n",
    "for name, model in [(\"Ridge\", ridge), (\"Lasso\", lasso), (\"ElasticNet\", elastic)]:\n",
    "    pred = model.predict(X_test_s)\n",
    "    print(f\"{name} - MSE: {mean_squared_error(y_test, pred):.4f}, R²: {r2_score(y_test, pred):.4f}\")\n",
    "    print(f\"  Coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **Scale features** (e.g. StandardScaler) before Ridge/Lasso/ElasticNet so the penalty is fair across features.\n",
    "- **Ridge**: Use when you want to keep all features but shrink coefficients.\n",
    "- **Lasso**: Use when you suspect many coefficients are zero (sparse model).\n",
    "- **ElasticNet**: Use when features are correlated and you want both shrinkage and some selection.\n",
    "- Tune **alpha** (and **l1_ratio** for ElasticNet) via **GridSearchCV** or **RidgeCV/LassoCV**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
