{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Ensemble Learning: Boosting\n",
    "\n",
    "**Purpose:** Learn and revise **Boosting** (AdaBoost, Gradient Boosting) in Scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Boosting?\n",
    "\n",
    "**Boosting** builds an ensemble **sequentially**: each new model focuses on the **mistakes** of the previous ones. AdaBoost reweights misclassified samples; Gradient Boosting fits new trees to the **residuals** of the current ensemble.\n",
    "\n",
    "**Key idea:** Many **weak learners** (e.g. shallow trees) combine into a strong one; reduces **bias**. Tune **n_estimators**, **learning_rate**, and **max_depth**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts to Remember\n",
    "\n",
    "| Concept | Description |\n",
    "|--------|-------------|\n",
    "| **AdaBoost** | Sample weights updated by errors; base estimator fit to weighted data. |\n",
    "| **Gradient Boosting** | Each tree fits residuals; learning_rate shrinks each contribution. |\n",
    "| **n_estimators** | Number of weak learners. |\n",
    "| **learning_rate** | Shrinks each model; smaller = need more estimators. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.randn(300, 4)\n",
    "y = (X[:, 0] + X[:, 1] ** 2 > 0.5).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost: 0.9666666666666667\n",
      "Gradient Boosting: 0.9333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.90        23\n",
      "           1       0.90      1.00      0.95        37\n",
      "\n",
      "    accuracy                           0.93        60\n",
      "   macro avg       0.95      0.91      0.93        60\n",
      "weighted avg       0.94      0.93      0.93        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "print(\"AdaBoost:\", accuracy_score(y_test, ada.predict(X_test)))\n",
    "print(\"Gradient Boosting:\", accuracy_score(y_test, gb.predict(X_test)))\n",
    "print(classification_report(y_test, gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **AdaBoostClassifier** / **GradientBoostingClassifier**; **HistGradientBoostingClassifier** for large data.\n",
    "- Tune **n_estimators** and **learning_rate**; **feature_importances_** available for tree-based boosters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning2fly-sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
