{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. K-Means Clustering\n",
    "\n",
    "**Purpose:** Learn and revise **K-Means** clustering in Scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "## What is K-Means?\n",
    "\n",
    "**K-Means** is an **unsupervised** algorithm that partitions \\( n \\) points into **k** clusters. It alternates:\n",
    "\n",
    "1. **Assign:** Each point is assigned to the **nearest centroid** (Euclidean distance).\n",
    "2. **Update:** Each centroid is set to the **mean** of all points assigned to it.\n",
    "\n",
    "This minimizes within-cluster sum of squares. The algorithm is iterative and can get stuck in local minima; **run multiple initializations** (n_init) and pick the best.\n",
    "\n",
    "**Key idea:** You must choose **k**; no labels. **Scale features.** Good for compact, roughly spherical clusters; sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts to Remember\n",
    "\n",
    "| Concept | Description |\n",
    "|--------|-------------|\n",
    "| **k** | Number of clusters; choose with elbow method, silhouette, or domain knowledge. |\n",
    "| **Centroid** | Center of each cluster (mean of assigned points). |\n",
    "| **n_init** | Number of random initializations; best run (lowest inertia) is kept. |\n",
    "| **When to use** | Unsupervised grouping; preprocessing; when clusters are roughly spherical. |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "X0 = np.random.randn(50, 2) + np.array([2, 2])\n",
    "X1 = np.random.randn(50, 2) + np.array([6, 6])\n",
    "X2 = np.random.randn(50, 2) + np.array([2, 6])\n",
    "X = np.vstack([X0, X1, X2])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_s = scaler.fit_transform(X)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "k = 3\n",
    "model = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "model.fit(X_s)\n",
    "labels = model.predict(X_s)\n",
    "centroids = model.cluster_centers_\n",
    "\n",
    "print(\"Inertia (within-cluster sum of squares):\", model.inertia_)\n",
    "print(\"Cluster sizes:\", np.bincount(labels))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(X_s[:, 0], X_s[:, 1], c=labels, alpha=0.7)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c=\"red\", s=200, marker=\"X\", edgecolors=\"k\")\n",
    "plt.xlabel(\"X1\"); plt.ylabel(\"X2\")\n",
    "plt.title(f\"K-Means (k={k})\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **KMeans(n_clusters=k)**; **fit** then **predict** or **fit_predict**; **cluster_centers_** and **inertia_** are key attributes.\n",
    "- Scale features; use **n_init** (e.g. 10) for stability. Choose k via elbow plot or **silhouette_score**.\n",
    "- **MiniBatchKMeans** for very large datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
  "language_info": { "name": "python", "version": "3.10.0" }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
